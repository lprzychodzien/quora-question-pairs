{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TheMedNet Data Challenge: Lukasz Przychodzien\n",
    "\n",
    "The goal is to identify if two questions are duplicates are not. Please submit a GitHub repository which includes a python notebook. Report your performance on the test set which is included. \n",
    "https://www.kaggle.com/c/quora-question-pairs/overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ID in the test set, you must predict the probability that the questions are duplicates (a number between 0 and 1). The file should contain a header and have the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id,is_duplicate\n",
    "0,0.5\n",
    "1,0.4\n",
    "2,0.9\n",
    "etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this competition is to predict which of the provided pairs of questions contain two questions with the same meaning. The ground truth is the set of labels that have been supplied by human experts. The ground truth labels are inherently subjective, as the true meaning of sentences can never be known with certainty. Human labeling is also a 'noisy' process, and reasonable people will disagree. As a result, the ground truth labels on this dataset should be taken to be 'informed' but not 100% accurate, and may include incorrect labeling. We believe the labels, on the whole, to represent a reasonable consensus, but this may often not be true on a case by case basis for individual items in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fields\n",
    "id - the id of a training set question pair\n",
    "\n",
    "qid1, qid2 - unique ids of each question (only available in train.csv)\n",
    "\n",
    "question1, question2 - the full text of each question\n",
    "\n",
    "is_duplicate - the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Submissions are evaluated on the log loss between the predicted values and the ground truth. Therefore, we are stiving for a lower log-loss value. \n",
    "\n",
    "https://www.kaggle.com/dansbecker/what-is-log-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lprzy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/lprzy/Documents/takehome/quora-question-pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis of Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Add visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of question pairs for training\n",
    "len(df_train.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24faeed59b0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24faeed59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.groupby(\"is_duplicate\")['id'].count().plot.bar(title='Total number of duplicate/nonduplicate pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.369197853026293"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percent of pairs that are duplicates\n",
    "len(df_train[df_train.is_duplicate==1])/len(df_train.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       1\n",
       "question2       2\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identifying any null values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the empty questions with the word empty\n",
    "df_train = df_train.fillna('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537933"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of unique question\n",
    "allqid = list(df_train.qid1)+list(df_train.qid2)\n",
    "unique_elem, counts_elem = np.unique(allqid, return_counts=True)\n",
    "len(unique_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111780"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of duplicate questions\n",
    "np.sum(counts_elem > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20779539459375052"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percent of duplicate questions of total questions\n",
    "np.sum(counts_elem > 1)/len(counts_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Maximum number of times one question appears in the dataset\n",
    "counts_elem.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allq = pd.Series(df_train.question1.tolist() + df_train.question2.tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808580"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of questions\n",
    "len(allq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1169"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Maximum number of characters found in a question\n",
    "allq.apply(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Maxium number of words found in a question\n",
    "allq.apply(lambda x: len(x.split(' '))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unqiue words in our corpus \n",
    "allq.apply(lambda x: len(x.split(' '))).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allq = allq.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the text by both stemming and lemmatization to see which brings the words to their root or canonical forms, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = CountVectorizer().build_tokenizer()\n",
    "\n",
    "def lemmed_words(doc):\n",
    "    return (lemmatizer.lemmatize(w) for w in tokenizer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our count vectorizers for word standardization\n",
    "cvl = CountVectorizer(stop_words='english', tokenizer=lemmed_words)\n",
    "cvs = CountVectorizer(stop_words='english', analyzer=stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function stemmed_words at 0x000001C78E10C378>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words='english', strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn the vocabulary of the stemmed questions\n",
    "cvs.fit(allq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function lemmed_words at 0x000001C78E10C840>,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn the vocabulary of the lemmed questions\n",
    "cvl.fit(allq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78368\n",
      "65362\n"
     ]
    }
   ],
   "source": [
    "#Entire vocabulary and integer count of the number of times \n",
    "#each word appeared in all the questions (tokenized)\n",
    "\n",
    "#Number of words on our vocabulary \n",
    "print(len(cvl.vocabulary_))\n",
    "print(len(cvs.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the questions based on the vocabulary \n",
    "doc_cvs_matrix = cvs.transform(allq)\n",
    "doc_cvl_matrix = cvl.transform(allq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808580, 65362)\n",
      "(808580, 78368)\n"
     ]
    }
   ],
   "source": [
    "#The shape of our matrix which is the questions are encoded into seperate words\n",
    "print(doc_cvs_matrix.shape)\n",
    "print(doc_cvl_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequencies Transformation (Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we used CountVectorizer, we just use the Tf-IDF transformer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create tf-idf transformer \n",
    "tf_transformer = TfidfTransformer()\n",
    "tf_transformer.fit(doc_cvs_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform each question into a count matrix\n",
    "cv_q1 = cvs.transform(df_train.question1)\n",
    "cv_q2 = cvs.transform(df_train.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform each set of questions into a tf-idf representation\n",
    "df_train_tfidf_q1 = tf_transformer.transform(cv_q1)\n",
    "df_train_tfidf_q2 = tf_transformer.transform(cv_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 65362)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tfidf_q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our X and y values for statistical modeling\n",
    "#X is the absolute difference between each pair of questions\n",
    "#y is the score we are trying to predict, whether duplicate or not\n",
    "\n",
    "X = abs(df_train_tfidf_q1 - df_train_tfidf_q2)\n",
    "y = df_train['is_duplicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models (stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training data into test and train data for our models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36855439694985564"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensuring that the train data is split between dupliate/nonduplicate\n",
    "y_train[y_train==1].count()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37069925053798014"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensuring that the test data is split between dupliate/nonduplicate\n",
    "y_test[y_test==1].count()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The predict_proba function returns probability of 0 and 1, respectively. \n",
    "#We need to only select the probability of 1 (same question)\n",
    "pred_lr = lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss_lr = log_loss(y_test, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6593365992323104"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76326, 0, 44961, 0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 200, min_samples_leaf = 2, max_features = 6, min_samples_split = 2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=6, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict_proba(X_test)[:,1]\n",
    "logloss_rf = log_loss(y_test, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6593365740708749"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76326, 0, 44961, 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "xgb = GradientBoostingClassifier()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "logloss_xgb = log_loss(y_test, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6593098355618345"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76332, 0, 44955, 0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_xgb).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequencies Transformation (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create tf-idf transformer \n",
    "tf_transformer = TfidfTransformer()\n",
    "tf_transformer.fit(doc_cvl_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform each question into a count matrix\n",
    "cv_q1 = cvl.transform(df_train.question1)\n",
    "cv_q2 = cvl.transform(df_train.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform each set of questions into a tf-idf representation\n",
    "df_train_tfidf_q1 = tf_transformer.transform(cv_q1)\n",
    "df_train_tfidf_q2 = tf_transformer.transform(cv_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 78368)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tfidf_q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our X and y values for statistical modeling\n",
    "#X is the absolute difference between each pair of questions\n",
    "#y is the score we are trying to predict, whether duplicate or not\n",
    "\n",
    "X = abs(df_train_tfidf_q1 - df_train_tfidf_q2)\n",
    "y = df_train['is_duplicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training data into test and train data for our models\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3699183400882676"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensuring that the train data is split between dupliate/nonduplicate\n",
    "y_train[y_train==1].count()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3675167165483523"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensuring that the test data is split between dupliate/nonduplicate\n",
    "y_test[y_test==1].count()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The predict_proba function returns probability of 0 and 1, respectively. \n",
    "#We need to only select the probability of 1 (same question)\n",
    "pred_lr = lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "logloss_lr = log_loss(y_test, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6576332453387124"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76712, 0, 44575, 0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 200, min_samples_leaf = 2, max_features = 6, min_samples_split = 2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=6, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict_proba(X_test)[:,1]\n",
    "logloss_rf = log_loss(y_test, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6576335419401186"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76712, 0, 44575, 0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "xgb = GradientBoostingClassifier()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "logloss_xgb = log_loss(y_test, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6576331797943757"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76712, 0, 44575, 0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_xgb).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization Results\n",
    "\n",
    "Stemming allowed us to reach a log loss of 0.6593\n",
    "Lemmatization allowed us to reach a log loss of 0.6576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-000890c95f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Returns the cosine of the angle between the two vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mXcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train_tfidf_q1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_train_tfidf_q2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m     \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    500\u001b[0m                                     maxval=nnz)\n\u001b[0;32m    501\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Returns the cosine of the angle between the two vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "Xcs = cosine_similarity(df_train_tfidf_q1,df_train_tfidf_q2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
